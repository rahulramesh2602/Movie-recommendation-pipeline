### **ğŸ¬ Movie Recommendation Pipeline | Modern Data Engineering AWS Project**  

## **ğŸ“Œ Introduction**  
The goal of this project is to **build an end-to-end automated movie recommendation system** using **Apache Airflow** and **AWS**. The system ingests raw movie rating data, preprocesses it, trains a recommendation model, and generates personalized movie suggestions.  

This project follows a **modern data engineering approach**, leveraging tools such as **AWS S3, Apache Airflow, Python, Scikit-learn, and Boto3** to build a scalable and automated pipeline.  

---

## **ğŸš€ Tools & Technologies Used**
- **Amazon S3** â€“ Storage for raw and preprocessed datasets  
- **Apache Airflow** â€“ Orchestration of the data pipeline  
- **Python** â€“ Data processing and machine learning  
- **Scikit-Learn & SciPy** â€“ Collaborative filtering using Singular Value Decomposition (SVD)  
- **Pandas & NumPy** â€“ Data transformation and manipulation  
- **Boto3** â€“ Interaction with AWS services  
- **Airflow XComs & Logs** â€“ Task communication and monitoring  

---

## **ğŸ“Œ Project Workflow**
```
                 +--------------------------+
                 |  Dataset (movies.csv, ratings.csv) |
                 +--------------------------+
                                |
                                v
    +---------------------------------------------------+
    | Task 1: Upload Raw Data to S3                     |
    | Script: `upload_to_s3.py`                         |
    +---------------------------------------------------+
                                |
                                v
    +---------------------------------------------------+
    | Task 2: Preprocess Data (Merge & Clean)           |
    | Script: `preprocess_data.py`                      |
    | - Downloads raw data from S3                      |
    | - Merges ratings & movie metadata                 |
    | - Uploads processed data back to S3               |
    +---------------------------------------------------+
                                |
                                v
    +---------------------------------------------------+
    | Task 3: Train SVD Recommendation Model           |
    | Script: `train_model.py`                         |
    | - Downloads preprocessed data from S3            |
    | - Trains SVD-based collaborative filtering model |
    | - Saves model (`svd_recommender.pkl`)            |
    +---------------------------------------------------+
                                |
                                v
    +---------------------------------------------------+
    | Task 4: Generate Movie Recommendations           |
    | Script: `recommend_movies.py`                    |
    | - Loads trained model                             |
    | - Predicts top `n` movies for a given user       |
    | - Logs recommendations & stores in XCom          |
    +---------------------------------------------------+
```

---

## **ğŸ“Œ Pipeline Implementation in Apache Airflow**
The entire workflow is automated using **Apache Airflow**, ensuring **end-to-end orchestration** of the recommendation pipeline.  

**DAG Structure (`movie_recommendation_pipeline.py`)**
1ï¸âƒ£ `upload_to_s3.py` â€“ Uploads raw `movies.csv` & `ratings.csv` to S3  
2ï¸âƒ£ `preprocess_data.py` â€“ Merges, cleans data & uploads `preprocessed_data.csv` to S3  
3ï¸âƒ£ `train_model.py` â€“ Downloads preprocessed data & trains SVD model  
4ï¸âƒ£ `recommend_movies.py` â€“ Generates movie recommendations & stores results  

---

## **ğŸ“Œ Installation & Setup**
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/yourusername/Movie-recommendation-pipeline.git
cd Movie-recommendation-pipeline
```

### **2ï¸âƒ£ Create a Virtual Environment & Install Dependencies**
```sh
python3 -m venv movie_rec
source movie_rec/bin/activate  # Mac/Linux
movie_rec\Scripts\activate     # Windows
pip install -r requirements.txt
```

### **3ï¸âƒ£ Configure AWS Credentials**
Ensure your AWS CLI is configured to interact with S3:
```sh
aws configure
```

### **4ï¸âƒ£ Start Apache Airflow**
```sh
export AIRFLOW_HOME=~/airflow
airflow db init
airflow webserver --port 8080 &
airflow scheduler &
```

### **5ï¸âƒ£ Deploy the Airflow DAG**
Move the DAG to the Airflow DAGs directory:
```sh
mv movie_recommendation_pipeline.py ~/airflow/dags/
airflow dags reload
```

---

## **ğŸ“Œ Running the Pipeline in Airflow**
### **1ï¸âƒ£ Start Airflow**
```sh
airflow webserver --port 8080 &
airflow scheduler &
```
- Open **http://localhost:8080** in your browser.

### **2ï¸âƒ£ Trigger the DAG Manually**
1. Navigate to the Airflow UI.
2. Find `movie_recommendation_pipeline`.
3. Click **Trigger DAG** â–¶ï¸ to start the pipeline.

---

## **ğŸ“Œ File Structure**
```
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ movies.csv
â”‚   â”œâ”€â”€ ratings.csv
â”‚
â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ upload_to_s3.py
â”‚   â”œâ”€â”€ preprocess_data.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ recommend_movies.py
â”‚   â”œâ”€â”€ models/                    # Trained model stored here
â”‚   â”‚   â”œâ”€â”€ svd_recommender.pkl
â”‚
â”œâ”€â”€ Dags/
â”‚   â”œâ”€â”€ movie_recommendation_pipeline.py  # Airflow DAG file
â”‚
â”œâ”€â”€ .flake8
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## **ğŸ“Œ Example Output**
```sh
ğŸ”„ Loading datasets...
âœ… Data preprocessing complete! 100836 ratings loaded.
ğŸš€ Training SVD model...
âœ… Model training complete!
ğŸ’¾ Model saved to Scripts/models/svd_recommender.pkl
ğŸ” Generating recommendations for User 1...
ğŸ¬ Top recommended movies:
ğŸ¥ The Godfather (Movie ID: 858)
ğŸ¥ Die Hard (Movie ID: 1036)
ğŸ¥ The Godfather: Part II (Movie ID: 1221)
ğŸ¥ Jaws (Movie ID: 1387)
ğŸ¥ The Breakfast Club (Movie ID: 1968)
```

---

## **ğŸ“Œ Future Enhancements**
âœ… **Enable Real-Time User Input for Personalized Recommendations**  
âœ… **Deploy the Model as a REST API (Using Flask or FastAPI)**  
âœ… **Store Predictions in a Database (PostgreSQL, DynamoDB, or S3 JSON)**  
âœ… **Integrate AWS Lambda & DynamoDB for Scalable Data Storage**  
âœ… **Visualize Insights in a Web Dashboard**  

---

## **ğŸ“œ License**
This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## **ğŸ¤ Contributing**
Want to improve the project? Feel free to open **Issues** & **Pull Requests**!

---

### **ğŸš€ Next Steps**
ğŸ”¹ **Add this `README.md` to your repository.**  
ğŸ”¹ **Test your pipeline & monitor it in Apache Airflow.**  
ğŸ”¹ **(Optional) Deploy as a REST API for real-time recommendations.**  

ğŸ”¥ **Now your project is well-documented & production-ready!** ğŸš€  
Let me know if you need any refinements! ğŸ˜Š